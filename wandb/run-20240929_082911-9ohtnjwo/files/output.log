INFO:lightning_fabric.utilities.seed:Seed set to 42
device: cpu
/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
BertConfig {
  "_name_or_path": "klue/bert-base",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.44.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 32000
}
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

--- Modeling Done ---
dataframe 의 형태
----------------------------------------------------------------------------------------------------
                             id  \
0  nikluge-au-2022-train-000001
1  nikluge-au-2022-train-000002
2  nikluge-au-2022-train-000003
3  nikluge-au-2022-train-000004
4  nikluge-au-2022-train-000005

                                               input  output
0  보여주면서 왜 엿보냐고 비난 하는것도 웃기지만. 훔쳐 보면서 왜 보여주냐고 하는 사...       1
1  왜 개인 사생활을 방송으로 보여주고 싶은지 이해도 안가지만 &location&식 프...       1
2  이런 쓰레기같은 새끼가 아무렇지 않게 멀쩡히 돌아다닐 생각을 하니까 진짜 너무 소름...       1
3                                       인간의 탈을 쓰고...       1
4                        인기글에 짱깨뭐라하니까 댓글로 ㅂㄷㅂㄷ하네요...       1
dataframe 의 형태
----------------------------------------------------------------------------------------------------
                           id  \
0  nikluge-au-2022-dev-000001
1  nikluge-au-2022-dev-000002
2  nikluge-au-2022-dev-000003
3  nikluge-au-2022-dev-000004
4  nikluge-au-2022-dev-000005

                                               input  output
0  그리고 민중은 개돼지니 신분제 공고화니 이러던 &name&도 정책 설명 때는 ``교...       1
1                                              꼴페미년들       1
2                                     &name& 잔머리 보소.       1
3                           벌써 오늘 쓸 체력의 7할은 소진한 듯...       0
4  특히 죄다 `약약약`인 &affiliation& 후보가 나와서 대체 뭐라고 하고서 ...       1
dataframe 의 형태
----------------------------------------------------------------------------------------------------
                            id  \
0  nikluge-au-2022-test-000001
1  nikluge-au-2022-test-000002
2  nikluge-au-2022-test-000003
3  nikluge-au-2022-test-000004
4  nikluge-au-2022-test-000005

                                               input  output
0                        극좌는 이 비겁자층을 제대로 요리할 줄 안다...     NaN
1                                 내가 진짜 올 해 안에 차 산다!     NaN
2  선거 때마다 불장난 하는 못된 버릇 대대손손 배워가지고 그러고 까불어대면, 너 나중...     NaN
3  난 99년도에 이미 세상은 망해서 선한자들은 이미 모두 하늘로 올라갔고, 남은 우리...     NaN
4                                피의자로 가는 싸가지 없는 쓰래기!     NaN
--- data loading Done ---
tokenizer 에 들어가는 데이터 형태
0    보여주면서 왜 엿보냐고 비난 하는것도 웃기지만. 훔쳐 보면서 왜 보여주냐고 하는 사...
1    왜 개인 사생활을 방송으로 보여주고 싶은지 이해도 안가지만 &location&식 프...
2    이런 쓰레기같은 새끼가 아무렇지 않게 멀쩡히 돌아다닐 생각을 하니까 진짜 너무 소름...
3                                         인간의 탈을 쓰고...
4                          인기글에 짱깨뭐라하니까 댓글로 ㅂㄷㅂㄷ하네요...
Name: input, dtype: object
tokenizing 된 데이터 형태
----------------------------------------------------------------------------------------------------
[Encoding(num_tokens=81, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=81, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]
tokenizer 에 들어가는 데이터 형태
0    그리고 민중은 개돼지니 신분제 공고화니 이러던 &name&도 정책 설명 때는 ``교...
1                                                꼴페미년들
2                                       &name& 잔머리 보소.
3                             벌써 오늘 쓸 체력의 7할은 소진한 듯...
4    특히 죄다 `약약약`인 &affiliation& 후보가 나와서 대체 뭐라고 하고서 ...
Name: input, dtype: object
tokenizing 된 데이터 형태
----------------------------------------------------------------------------------------------------
[Encoding(num_tokens=51, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=51, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]
tokenizer 에 들어가는 데이터 형태
0                          극좌는 이 비겁자층을 제대로 요리할 줄 안다...
1                                   내가 진짜 올 해 안에 차 산다!
2    선거 때마다 불장난 하는 못된 버릇 대대손손 배워가지고 그러고 까불어대면, 너 나중...
3    난 99년도에 이미 세상은 망해서 선한자들은 이미 모두 하늘로 올라갔고, 남은 우리...
4                                  피의자로 가는 싸가지 없는 쓰래기!
Name: input, dtype: object
tokenizing 된 데이터 형태
----------------------------------------------------------------------------------------------------
[Encoding(num_tokens=53, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=53, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]
--- data tokenizing Done ---
--- pytorch dataset class Done ---
/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
--- Set training arguments Done ---
--- Set Trainer Done ---
--- Start train ---
[main 3b10063] Your commit message
 23 files changed, 1451 insertions(+), 4 deletions(-)
 create mode 100644 __pycache__/data.cpython-310.pyc
 create mode 100644 __pycache__/model.cpython-310.pyc
 create mode 100644 __pycache__/utils.cpython-310.pyc
 create mode 120000 wandb/debug-internal.log
 create mode 120000 wandb/debug.log
 create mode 120000 wandb/latest-run
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/files/config.yaml
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/files/output.log
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/files/requirements.txt
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/files/wandb-metadata.json
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/files/wandb-summary.json
 create mode 120000 wandb/run-20240929_082826-o3wmfrv9/logs/debug-core.log
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/logs/debug-internal.log
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/logs/debug.log
 create mode 100644 wandb/run-20240929_082826-o3wmfrv9/run-o3wmfrv9.wandb
 create mode 100644 wandb/run-20240929_082911-9ohtnjwo/files/output.log
 create mode 100644 wandb/run-20240929_082911-9ohtnjwo/files/requirements.txt
 create mode 100644 wandb/run-20240929_082911-9ohtnjwo/files/wandb-metadata.json
 create mode 120000 wandb/run-20240929_082911-9ohtnjwo/logs/debug-core.log
 create mode 100644 wandb/run-20240929_082911-9ohtnjwo/logs/debug-internal.log
 create mode 100644 wandb/run-20240929_082911-9ohtnjwo/logs/debug.log
 create mode 100644 wandb/run-20240929_082911-9ohtnjwo/run-9ohtnjwo.wandb
error: src refspec test does not match any
[31merror: failed to push some refs to 'https://github.com/kkkimin/hate_classification.git'
[m
